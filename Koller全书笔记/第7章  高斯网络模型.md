### 第七章  高斯网络模型

 	前面讨论的贝叶斯网络和马尔可夫网络都是对于离散变量谈论的，对于连续变量空间对应可以采用高斯贝叶斯网和高斯马尔可夫网模型建模描述。

#### 7.1  多元高斯分布

##### 7.1.1  基本参数化方法

 对于$X_{1}, \cdots, X_{n}$上的多元高斯分布，由$n$维均值向量$\mu$，以及$n \times n$对称协方差矩阵$\Sigma$定义，概率密度函数定义如下：
$$
p(x)=\frac{1}{(2 \pi)^{n / 2}|\Sigma|^{1 / 2}} \exp \left[-\frac{1}{2}(x-\mu)^{\mathrm{T}} \Sigma^{-1}(x-\mu)\right]
$$
其中，$|\Sigma|$是$\Sigma$的行列式。此外，将标准高斯分布也从一维推广到多维：均值向量为0，协方差矩阵是对角线元素为1、其余元素为0的单位矩阵【不难看出，协方差矩阵是单位矩阵情况下，概率密度函数很容易进行因子分解，得到随机变量之间两两互斥的结论】。此外，为使概率密度函数有意义，需限定$\Sigma$正定（二次型大于0，或者行列式顺序主子式大于0）

由于正定矩阵可逆，经常将协方差逆矩阵直接表示为$J=\Sigma^{-1}$，$J$称为**信息矩阵**（information matrix）或**精度矩阵**（precision matrix）。（引入该矩阵是为了定义条件独立性）。

可以观察到，正态分布的指数函数形式类似于马尔可夫网因子分解后的对数线性模型形式，可以考虑能否直接利用这个形式得到类似的因子分解，于是：
$$
\begin{equation}
p(x)=\frac{1}{(2 \pi)^{n / 2}|\Sigma|^{1 / 2}} \exp \left[-\frac{1}{2}(x-\mu)^{\mathrm{T}} \Sigma^{-1}(x-\mu)\right] \\
\propto \exp \left[-\frac{1}{2}(x-\mu)^{\mathrm{T}} \Sigma^{-1}(x-\mu)\right]  \\
= \exp \left[-\frac{1}{2}(x-\mu)^{\mathrm{T}} J (x-\mu)\right]  \\
= \exp \left[-\frac{1}{2}\left(x^{\top} J x-2 x^{\top} J \mu+\mu^{\top} J \mu\right)\right]  \\
\propto \exp \left[-\frac{1}{2}\left(x^{\top} J x-2 x^{\top} J \mu\right)\right] 
\end{equation}
$$
上述形式其实已经接近马尔可夫网的势函数形式，对于特定变量能够表征节点和边位势，放到后面再讨论就会很明白（建议直接跳过这里，到高斯马尔可夫网看看推导过程再回来，更容易理解）。得到的结果为：
$$
p(x) \propto \exp \left[-\frac{1}{2} x^{T} J x+(J \mu)^{T} x\right]
$$
该公式称为高斯密度函数的**信息形式**（information form），并且$h=J \mu$称为**位势向量**（potential vector）。

补充几个概率论知识：多维和一维的情况类似，均值向量和协方差矩阵依然是正态分布的一阶矩和二阶矩：$\mu=E[X]$以及$\Sigma=E\left[X X^{\mathrm{T}}\right]-E[X] E[X]^{\top}$，其中$X$是向量，在单变量上$\mu_{i}$是$X_{i}$的均值，对角线$\Sigma_{i, i}$是$X_{i}$的方差，$\Sigma_{i, j}=\Sigma_{j, i}$为$X_{i}$和$X_{j}$的协方差$\operatorname{Cov}\left[X_{i} ; X_{j}\right]=E\left[X_{i} X_{j}\right]-E\left[X_{i}\right] E\left[X_{j}\right]$。

##### 7.1.2  高斯分布的运算

主要包括两种常用运算：边缘分布和给定条件下的条件分布。（这部分的证明见[入口1](https://keson96.github.io/2017/03/03/2017-03-03-Probability-Distribution-Basics-2/) |  [入口2](https://seanwangjs.github.io/2018/01/08/conditional-gaussian-distribution.html)）

对边缘分布而言，采用定义形式很容易获得结果，如假定$\{X, Y\}$上的一个联合正态分布，其中$\boldsymbol{X} \in \boldsymbol{R}^{n}, \boldsymbol{Y} \in \boldsymbol{R}^{m}$，联合分布的参数为：$p(X, Y)=\mathcal{N}\left(\left(\begin{array}{l}{\mu_{X}} \\ {\mu_{Y}}\end{array}\right) ;\left[\begin{array}{ll}{\Sigma_{X X}} & {\Sigma_{X Y}} \\ {\Sigma_{Y X}} & {\Sigma_{Y Y}}\end{array}\right]\right)$，其中$\mu_{X} \in R^{n}, \quad \mu_{Y} \in R^{m}$，$\sum_{X X}$是$n \times n$矩阵，$\sum_{X Y}$是$m \times n$矩阵，$\sum_{Y Y}$是方法是$m \times m $矩阵，则边缘分布的获取有如下定理：

* 引理7.1
令$\{\boldsymbol{X}, \boldsymbol{Y}\}$是上式定义的联合正态分布，则$\boldsymbol{Y}$上的边缘分布是正态分布$\mathcal{N}\left(\mu_{y} ; \Sigma_{Y Y}\right)$。

条件分布计算可以采用信息形式，直接将观测变量$Z=z$带进去即可。

确定多维高斯分布的关键在于协方差矩阵的计算，该矩阵规模为变量的二次方，且存在逆矩阵求解，计算很大，所以为是其具有现实意义需要考虑其独立性。
##### 7.1.3  高斯分布的独立性

* 定理7.1
  令$X=X_{1}, \cdots, X_{n}$有联合正态分布$\mathcal{N}(\mu ; \Sigma)$，那么$X_{i}$和$X_{j}$独立，当且仅当$\Sigma_{i, j}=0$。
  证明：协方差为0说明不相关，而高斯分布中不相关和独立是等价的。【注意】这里的独立是绝对独立性、边缘独立性，不是条件独立，为了构造和展示高斯网络的条件独立性，需要进一步讨论。

* 定理7.2  
  考虑高斯分布$p\left(X_{1}, \cdots, X_{n}\right)=\mathcal{N}(\mu ; \Sigma)$，且令$J=\Sigma^{-1}$为其信息矩阵，则$J_{i, i}=0$当且仅当$p\left|=\left(X_{i} \perp X_{j} | \mathcal{X}-\left\{X_{i}, X_{j}\right\}\right.\right.$。
  根据进一步的推导得到单变量形式看出，上述定理意思是：（2）信息矩阵某非对角元素为0，意味着对应的两个节点之间没有依赖（2）两节点条件独立，给定其他所有节点意味着抛开这两节点之外依然是独立的（也就是说，其他节点依然不提供连通这两个节点的路径）

  【注意】 区别于边缘独立性，前者是给定协方差矩阵的$\Sigma_{i, j}=0$，条件独立性是其逆矩阵$J_{i, i}=0$。

因此，利用上面的独立性知，信息矩阵可以视为直接为$p$定义了一个I-map的马尔可夫网，其中非零表值对应与网络中的边。
#### 7.2  高斯贝叶斯网

	下面用贝叶斯网来定义连续的高斯分布。

* 定义7.1
  高斯贝叶斯网定义为其所有变量都是连续的，并且其中的所有CPD都是线性高斯的贝叶斯网。

高斯贝叶斯网是建立在线性高斯模型上的。即从局部来看，高斯贝叶斯网是当前节点在给定父节点下的线性高斯模型。下面逐步证明：

（1）首先回顾高斯线性模型的定义：$P(Y | \boldsymbol{x})=\mathcal{N}\left(\beta_{0}+\boldsymbol{\beta}^{\mathrm{T}} \boldsymbol{x} ; \sigma^{2}\right)$，变量$Y$是$X_{1}, \cdots, X_{k}$外加均值0方差$\sigma^{2}$的线性函数：$Y=\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{k} x_{k}+\epsilon$，其中$\epsilon$是均值0方差$\sigma^{2}$的高斯噪声（例如给定$X_{1}=x_1, \cdots, X_{k}=x_k$情况下，$Y$服从均值$\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{k} x_{k}$、方差$\sigma^{2}$的正态分布）。

（2）现有节点$x_{i}$，其父节点$x_{p a(i)}=\left(x_{1}, x_{2}, \cdots, x_{k}\right)^{\top}$，可以写出其线性高斯表示：
$$
P\left(x_{i} | x_{pa(i)}\right)=N\left(x_{i} | \mu_{i}+w_{i}^{T} x_{p a(i)}, \sigma_{i}^{2}\right)
$$
则变量：
$$
x_{i}=\mu_{i}+\sum_{j \in x_{p a(i)}} w_{i j} \cdot\left(x_{j}-\mu_{j}\right)+\sigma_{i} \cdot \varepsilon_{i}
$$
其中$\varepsilon_{i} \sim N(0,1)$，进而可以两边同时取均值和方差以及协方差，得到正态分布$x_{i}$的参数。总结如下：

* 定理7.3
  令$Y$是其父亲节点$X_{1}, \cdots, X_{k}$的线性高斯$p(Y | \boldsymbol{x})=\mathcal{N}\left(\beta_{0}+\boldsymbol{\beta}^{\mathrm{T}} \boldsymbol{x} ; \sigma^{2}\right)$，假定$X_{1}, \cdots, X_{k}$是具有分布$\mathcal{N}(\mu ; \Sigma)$的联合高斯，则：

  * $Y$的分布是一个正态分布$p(Y)=\mathcal{N}\left(\mu_{y} ; \sigma_{Y}^{2}\right)$，其中：
    $$
    \begin{aligned}
    &\mu_{y}=\beta_{0}+\beta^{\mathrm{T}} \mu\\
    &\sigma_{\gamma}^{2}=\sigma^{2}+\beta^{\mathrm{T}} \Sigma \beta
    \end{aligned}
    $$
    
  *  $\{x, Y\}$上的联合分布是一个正态分布，其中：$\operatorname{Cov}\left[X_{i} ; Y\right]=\sum_{j=1}^{k} \beta_{j} \Sigma_{i, j}$  

* 定理7.4
  令$\{X, Y\}$有分布$p(\boldsymbol{X}, \boldsymbol{Y})=\mathcal{N}\left(\left(\begin{array}{c}{\boldsymbol{\mu}_{X}} \\ {\boldsymbol{\mu}_{Y}}\end{array}\right) ;\left[\begin{array}{cc}{\Sigma_{X X}} & {\Sigma_{X Y}} \\ {\Sigma_{Y X}} & {\Sigma_{Y Y}}\end{array}\right]\right)$，则条件密度$p(Y | \boldsymbol{X})=\mathcal{N}\left(\beta_{0}+\beta^{\mathrm{T}} \boldsymbol{X} ; \sigma^{2}\right)$使得：
  $$
  \begin{aligned}
  &\beta_{0}=\mu_{Y}-\Sigma_{Y X} \Sigma_{X X}^{-1} \mu_{X}\\
  &\beta=\Sigma_{X X}^{-1} \Sigma_{\gamma X}\\
  &\sigma^{2}=\Sigma_{V Y}-\Sigma_{Y X} \Sigma_{X X}^{-1} \Sigma_{Y 1}
  \end{aligned}
  $$
该结果允许我们选择一个联合高斯分布，并生成一个贝叶斯网。
  
* 定理7.5
  令$\mathcal{X}=\left\{X_{1}, \cdots, X_{n}\right\}$，且令$p$为$\mathcal{X}$上的联合高斯分布，给定$\mathcal{X}$上的任意一个$X_{1}, \cdots, X_{n}$序，可以构建贝叶斯网图$\mathcal{G}$以及$\mathcal{G}$上的贝叶斯网$\mathcal{B}$，使得：

  * $P a_{X}^{G} \subseteq\left\{X_{1}, \cdots, X_{i-1}\right\}$
  * $X_{i}$在$\mathcal{B}$中的CPD是其父节点的线性高斯分布
  * $\mathcal{G}$是$p$的最小I-map

高斯分布与高斯贝叶斯网之间的等价性有十分重要的现实后果。一方面，可以推断，对于线性高斯网络，联合分布有紧凑的表示（这种表示是变量个数的平方量级，平方主要体现在协方差矩阵的规模，然而实际上根据对称和独立性可以进一步约简和稀疏化）。此外，从网络到联合的转换以及反向的转换有相当简单而有效的可计算**闭型**（closed form)（闭型相当于微分方程的解析解，即提供解决问题的一种严格范式）。

注：线性高斯模型和高斯模型的表示能力等价，但是参数之间没有严格一一对应关系。

#### 7.3 高斯马尔可夫随机场

在本章开始对多元高斯分布概率密度函数的演化得到结果为：
$$
p(x) \propto \exp \left[-\frac{1}{2} x^{T} J x+(J \mu)^{T} x\right]
$$
其实已经能看出括号内第一项为E二次型，第二项为一次项，和能量函数的形式类似了。进一步地，考虑随机变量向量中的每个元素产生的影响：

对于$x=[\begin{array}{l}{x_{1}} \ {x_{2}} \ {\dots} \ {x_{p}}\end{array}]^T$，和$J=\left(\lambda_{i j}\right)_{p \times p}$，令$h=J \mu$称之为位势向量（potential vector），且$h=[\begin{array}{l}{h_{1}} \ {h_{2}} \ {\dots} \ {h_{p}}\end{array}]^T$，展开得到与$x_{i}$相关的项有：$-\frac{1}{2} x_{i}^{2} \cdot \lambda_{i i}+h_{i} x_{i}$，与$x_{i}. x_{j}$ 相关的项有：$-\frac{1}{2}\left(\lambda_{i j} x_{i} x_{j}+\lambda_{j i} x_{j} x_{i}\right)=-\lambda_{i j} x_{i} x_{j}$。其中，只和单个节点$x_{i}$相关的函数可以类比为能量函数中的节点位势$\psi_{i}\left(x_{i}\right)$，而与一对节点相关的函数类比为能量函数的边位势$\psi_{i, j}\left(x_{i}, x_{j}\right)$。

观察上述表示，（1）如果$\lambda_{i j} =0$，意味着两节点之间不存在直接连接的路径，那么在给定其他节点的情况下是独立的，对应成对马尔可夫性 （2）对于（1）进一步推知，信息形式可以由成对马尔可夫网表征。总的来说：任一高斯分布都可以被表示为有二次节点位势和边位势的成对尔可夫网。这种MRF称为**高斯马尔可夫随机场**（GMRF）。

注意的是，并非每个二次节点位势和边位势都能导出合法的高斯分布，因为上述二次型展开推理针对任意二次型都是成立的，没有进行对称正定性的约束。<u>检测GMRF有效性的唯一方法是测试信息矩阵是否正定</u>。但是也有一些单向成立的条件：

* 命题7.1
令$p^{\prime}(x)=\exp \left(-\frac{1}{2} x^{\tau} J x+h^{\top} x\right)$是一个二次成对MRF，如果$J$是对角占优的，则$p^{\prime}$定义了一个有效的GMRF.
（对角占优是指对角线的元大于等于该行所有其他元素模值之和）

对于非线性部分可以进一步讨论：首先将节点和边的能量函数记为如下一般化形式：
$$
\begin{aligned}
&\epsilon_{i}\left(x_{i}\right)=d_{0}^{i}+d_{1}^{i} x_{i}+d_{2}^{i} x_{i}^{2}\\
&\epsilon_{i, j}\left(x_{i}, x_{j}\right)=a_{00}^{i, j}+a_{01}^{i, j} x_{i}+a_{10}^{j, i} x_{j}+a_{11}^{i, j} x_{i} x_{j}+a_{02}^{i, j} x_{i}^{2}+a_{20}^{i, j} x_{j}^{2}
\end{aligned}
$$
* 定义7.3
  *		对于所有的$i$，$d_{2}^{i}>0$；
  *		对于所有的$i，j$，$2 \times 2$矩阵$\left(\begin{array}{cc}{a_{02}^{i, j}} & {a_{11}^{i, j} / 2} \\ {a_{11}^{i, j} / 2} & {a_{20}^{i, j}}\end{array}\right)$是半正定的
则上面一般化形式参数化的二次马尔可夫随机场称为**可两两正规化的**（pairwise normalizable）。（直观判断：点位势为正，边位势矩阵正定）


* 命题7.2
令$p^{\prime}(x)$是二次成对马尔可夫随机场，如果$p^{\prime}(x)$是可两两正规划的，则$p^{\prime}(x)$定义了一个有效的高斯分布。（充分但不必要）

---