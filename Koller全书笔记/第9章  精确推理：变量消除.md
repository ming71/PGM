### 第九章  精确推理：变量消除

推理实际就是求取概率：边缘概率、条件概率、最大后验。其中inference分为近似推断和精确推断。具体细分如下：



<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581686074760.png" alt="1581686074760" style="zoom:50%;" />

本章关注的重点就是精确推断的变量消除法。

#### 9.1  复杂性分析

图模型的推理问题是一个np难问题。本章分析主要集中于贝叶斯网，因为任意贝叶斯网可以在不增加规模的情况下化为马尔可夫网。复杂的理论性分析就略过，下面用一个简单的例子来论证这一点。

* 引例
考虑一个最简单的马尔科夫链$A \rightarrow B \rightarrow C \rightarrow D$，简单起见假设每个随机变量都是二值的，现在要求边缘概率$P(d)$。很容易得到，首先写出chain rule的形式，然后对三个变量分别取两种值得到八个因子和，分析得到：

$$
\begin{aligned}
P(d) &=\sum_{a, b, c} P(a, b, c, d) \\
&=\sum_{a, b, c} P(a) \cdot P(b | a) \cdot P(c | b) \cdot P(d | c) \\
&=P(a=0) \cdot P(b=0 | a=0) \cdot P(c=0 | b=0) P(d=0 | c=0) \\
&+P(a=1) \cdot P(b=0 | a=1) \cdot P(c=0 | b=0) \cdot P(d=0 | c=0) \\
& \vdots \\
&+P(a=1) \cdot P(b=1 | a=1) \cdot P(c=1|b=1) \cdot P(d=1 | c=1)
\end{aligned}
$$

	上面结果而言，因子和计算结果和变量个数成指数增长。所以这里的chain rule只是形式上简化了，没有进行计算上的约简。

#### 9.2  变量消除：基本思路

还是上面的结果。实际上我们可以根据贝叶斯网的独立性得到一些先验知识进行简化的，落实到计算中不难发现，在对$a$积分/求和的时候，$b、c$相关的项是可以作为常数提出来的，从而先计算$a$的边缘分布而消去了$a$；之后依次消除其他项，因此可以由chain rule得到：
$$
\begin{aligned}
&=\sum_{b, c} p(c | b)|\cdot p(d | c) \cdot \underbrace{\sum_{a} P(a)\cdot p(b | a)}_{\phi_a(b)}\\
&=\sum_{c}(d | c) \cdot \underbrace{\sum_{b} p\left(c|b) \cdot \phi_{a}(b)\right.}_{\phi_{b}(c)}\\
&=\phi_{c}(d)
\end{aligned}
$$
其中以一个为例，$\phi_{c}(d)$是$d$的函数，是约简$c$后得到的。从形式上来说，左右表示的都是边缘分布$P(d)$，重要的是这个消去变量简化计算的思想，这就是精确推理的**变量消除（VE）**的基本思想，一言以蔽之：利用动态规划的思想，**交换乘积和求和运算的顺序，逐步对非查询变量进行消元**。

#### 9.3  变量消除

为了使得算法同时适用于贝叶斯网和马尔可夫网，我们采用因子的定义方法，使得算法具有一般性。

##### 9.3.1  基本消除

###### 9.3.1.1  因子边缘化

从之前的推理不难看出，<u>变量消除的关键思想就是对变量进行边缘化，求取边缘分布从而使之从计算式中被积分或求和而消除</u>。这种边缘分布计算的方法可以看做基于因子的计算：

* 定义9.3
  令$\boldsymbol{X}$是变量的一个集合，$Y$是满足$Y \notin X$的变量。令$\phi(\boldsymbol{X}, Y)$是一个因子，$Y$在$\phi$中的因子边缘化定义为使得：
  $$
  \psi(X)=\sum_{Y} \phi(X, Y)
  $$
的因子$\boldsymbol{X}$的因子$\phi$，记作$\sum_{Y} \phi$。这个运算也称**作在$\psi$中对$Y$求和**。

###### 9.3.1.2  变量消除算法

在章首给出的实例中，联合分布可表示为$P(A, B, C, D)=\phi_{A} \cdot \phi_{A} \cdot \phi_{C} \cdot \phi_{D}$，要求取的边缘分布为$P(D)=\sum_{C} \sum_{B} \sum_{A} P(A, B, C, D)$，利用上面定义的因子形式：
$$
\begin{aligned}
P(D) &=\sum_{C} \sum_{B} \sum_{A} \phi_{A} \cdot \phi_{B} \cdot \phi_{C} \cdot \phi_{D} \\
&=\sum_{C} \sum_{B} \phi_{C} \cdot \phi_{D} \cdot\left(\sum_{A} \phi_{A} \cdot \phi_{B}\right) \\
&=\sum_{C} \phi_{D} \cdot\left(\sum_{B} \phi_{C} \cdot\left(\sum_{A} \phi_{A} \cdot \phi_{B}\right)\right)
\end{aligned}
$$
该算法就是**和-积变量消除算法**（sum-product variable elimination，VE）。算法的基本思想是每次对一个变量求和。当对一个变量求和时，我们可以用所有与该变量相关的因子作积，然后从组合因子中对这个变量求和，依次递归。

在用于马尔可夫网时，这些因子简单地表示为团势能，处理方法相同。只是注意无向图多了个配分函数，需要化到每个因子里面，即对每个因子作归一化计算即可。

* **例9.1：扩展的学生贝叶斯网中的变量消除**

这个例子不错，可以仔细看看，用一个和马尔科夫链相比稍微复杂点的学生贝叶斯网来进行变量消除，进而求取获得工作可能性的边缘概率。

###### 9.3.1.3  因子语义

很多例子中（如之前的马尔可夫链和上面的学生贝叶斯），因子与网络中的条件概率或边缘概率相对应。这个现象可以加深理解，但是这个现象并不总是成立的。该部分给出了一个例子，可以作为参考。（但是步骤上来说，只要严格遵照变量消除的形式即可）

##### 9.3.2  证据处理

引入证据，或者说是上下文，即需要求取与之前讨论的边缘分布相对应——这里求取的是给定上下文的条件概率。

* Cond-Prob-VE算法：
  给定$\mathcal{K}$为变量集$\mathcal{X}$上的一个网络，$Y$为查询变量的集合，$E=e$为证据集，参数化$\mathcal{K}$的因子表示为$\mathbf{\Phi}$，算法如下：

  * 用$\phi(E=e)$替换每个$\phi \in \mathbf{\Phi}$
  * 选择变量消除顺序$\prec$
  * $Z \leftarrow=\mathcal{X}-Y-E$
  * $\left.\phi^{*} \leftarrow \text { Sum-Product-VE}(\Phi, \prec, Z\right)$
  * $\alpha \leftarrow \sum_{y \in V a l(Y)} \phi^{*}(y)$
  * 返回$\alpha, \phi^{*}$

  其中$\alpha$是引入证据后重新归一化分布的归一化参数。

#### 9.4  复杂度与图结构：变量消除

##### 9.4.1  简单分析

上面关注的都是贝叶斯网，贝叶斯网中显然随机变量个数和初始因子个数一致（每个随机变量都是一个CPD一一对应）；而马尔可夫网中由于因子分解定义存在团上，节点位势和边位势会导致因子数大于变量数。但是思路是一样的，依然可以用相同的VE方法递归地消除中间变量。

分析略，可以参照书上对应部分。结果而言，VE算法的计算代价由产生的中间因子规模而定，并随因子中变量个数增长而指数增长。

##### 9.4.2  图论分析

上面得出基本结论即因子规模直接影响了计算代价，下面根据图结构来重新表达这种复杂性的分析。

###### 9.4.2.1  因子与无向图

关于因子和图的讨论不用关注其是否有向，因为有向图可以通过道德化化为无向图，而无向图的因子分解形式更为一般化，故下面都以无向图来推断。

###### 9.4.2.2  作为图变换的消除

考虑变量消除在因子集和马尔可夫网上的影响。以一个例子引入，如下图仍是学生分布。在上面提到的VE算法，先消去C（D的唯一父节点），后得到图（a），因为消除的条件概率只有cd相关的；消除D时，和式为$\phi(d,g)$和$\phi(d,i)$以及消去C得到的$\phi_c(d)$，按照步骤，首先会生成一个包含所有节点的一个最小团的团位势$\phi(d,i,g)$，然后通过积分式求取边缘概率消去D，得到$\phi_d(i,g)$，从而新的信息会在I和G之间建立联系但是原来本身就有联系，所以不用额外加边；对于消去I同理，加边，这条边称为填充边。

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581771479838.png" alt="1581771479838" style="zoom:67%;" />

###### 9.4.2.3  导出图

变量消除算法不同步骤导出的所有图的联合体称为其导出图，或诱导图，具体定义见9.5。书上有学生网络的导出图实例。下面介绍导出图的性质：

* 定理9.6
  令$\mathcal{I}_{\Phi, \prec}$是因子集$\Phi$和某个消除顺序$\prec$的诱导图，则：

  * 变量消除过程产生的每个因子的辖域是$\mathcal{I}_{\Phi, \prec}$的一个团
  * $\mathcal{I}_{\Phi, \prec}$中每个最大团在计算中是某个中间因子的辖域

  其实可见，中间变量在最大团和因子分解之间搭起了桥梁。

##### 9.4.3  寻找消除顺序

参见链接：[寻找消除顺序方法](https://www.cnblogs.com/ironstark/p/5137754.html)

#### 9.5  条件作用



---