### 第四章  无向图模型

对于变量之间交互影响无法指定方向的现象往往使用无向图建模更有效，本部分讨论的关注点集中于离散状态空间的分布上。

#### 4.1  误解示例

如第三章提到的四个学生组队作业案例，ABCD之间不需要明确的方向指示，互相的影响是对称的，这就可以用无向图来表征，第三章对应的图就是无向图——马尔可夫网络。然后就需要关注如何参数化这个马尔可夫网络进行有效建模。由于图中交互的无向性，无法像之前一样在给定其他节点时在一个节点上表示分布的标准CPD。与之对应需要的是一种对称的参数化方法。直观上量化的方法是衡量两个节点之间的亲密度（affinities），将相邻节点与一个具有通用目标的函数关联起来，这个函数称为一个因子（factor）。

* 因子（factor）：假定$D$是随机变量的集合，因子$\phi$定义为从$\operatorname{Val}(D)$映射到实数域$R$的一个函数。假如因子的所有表值都是非负的，称该因子是非负的。变量$D$称为因子的辖域，记为 $Scope[\phi]$。（一般未说明情况下只关注非负因子）
   例如学生合作例子中，要表达A和B的意见一致可能性大于意见分歧这一事实，可以用一个因子$\phi_{1}(A, B):   \operatorname{Val}(A, B) \mapsto R$表示，该因子是一个与a,b取值相关的值，代表二者之间的关联性，$\phi_{1}(a, b)$值越大，两个值的相容性越高。

* 配分函数（partition function）：与贝叶斯网络相似，马尔可夫网络的参数化也是从直接相关的变量之间定义局部的交互影响，为了定义全局模型，同样要对这些影响进行组合。方法是将局部因子相乘定义该分布，然后将其归一化使之成为合规的分布，如下：
$$
  P(a, b, c, d)=\frac{1}{Z} \phi_{1}(a, b) \cdot \phi_{2}(b, c) \cdot \phi_{3}(c, d) \cdot \phi_{4}(d, a)
$$
其中：  
$$
Z=\sum_{a, b, c, d} \phi_{1}(a, b) \cdot \phi_{2}(b, c) \cdot \phi_{3}(c, d) \cdot \phi_{4}(d, a)
$$
  是一个归一化的常数，称之为配分函数。

这种表示方法的好处是，对于表示变量之间的交互影响给予了很大的灵活性；坏处是理解因子改变带来的影响会带来困难。

#### 4.2  参数化

 	为了表示分布，需要像用CPD参数化有向图那样给图结构关联一个参数集，但是这里无向图的参数因子不能直接理解成概率或是条件概率，因此马尔可夫网的参数化并不直观。下面一步步引出该网络参数化的方法。

##### 4.2.1  因子

一个引例：首先按照贝叶斯网的逻辑来考虑这个参数化方式：将参数与节点之间的边相联系。考虑一个全连通图$\mathcal{X}$，对其不做任何独立性假设，则可以图上指定一个任意的联合分布，假设所有变量是二值的，共有n元变量，那么每条边上需要4个参数才能列举出成对节点的概率情况，对于所有变量共有$4\left(\begin{array}{l}{n} \\ {2}\end{array}\right)$个参数，而这对于指定该联合分布需要的参数$2^{n}-1$个是明显不够的！因此成对因子表示的方法不能覆盖整个联合分布的表示空间。那该怎么办？

可以联想到，既然直观的成对因子描述变量交互影响的办法不可取（虽然这种表示很直观），可以考虑推广到将因子定义在任意变量子集上获得。为此需要定义因子之间的运算。

* 定义4.2 
  令$X, \quad Y, \quad Z$是三个不相交的变量集，$\phi_{1}(\boldsymbol{X}, \boldsymbol{Y})$和$\phi_{2}(\boldsymbol{Y}, \boldsymbol{Z})$是定义在这些多变量集上的因子，因子乘积$\phi_{1} \times \phi_{2}$可以定义为一个新的因子$\psi: \operatorname{Val}(\boldsymbol{X}, \boldsymbol{Y}, \boldsymbol{Z}) \mapsto \mathbb{R}$：
$$
\psi(X, Y, Z)=\phi_{1}(X, Y) \cdot \phi_{2}(Y, Z)
$$
实际上，贝叶斯网也可以用类似的表示方法。

##### 4.2.2  吉布斯分布与马尔可夫网

现在利用上面地因子乘积来定义分布的无向参数化。

* 定义4.3
  假如分布$P_{\Phi}$定义如下：
  $$
  P_{\mathrm{ff}}\left(X_{1}, \cdots, X_{n}\right)=\frac{1}{Z} \tilde{P}_{\mathrm{u}}\left(X_{1}, \cdots, X_{n}\right)
  $$
其中：$\tilde{P}_{\mathrm{cp}}\left(X_{1}, \cdots, X_{n}\right)=\phi_{1}\left(D_{1}\right) \times \phi_{2}\left(D_{2}\right) \times \cdots \times \phi_{m}\left(D_{m}\right)$是归一化度量，且：$Z=\sum_{X_{1}, \cdots, X_{n}} \tilde{P}_{\mathrm{ft}}\left(X_{1}, \cdots, X_{n}\right)$是通常称为配分函数的归一化常数，那么分布$P_{\Phi}$称为由因子集$\Phi=\left\{\phi_{1}\left(D_{1}\right), \cdots, \phi_{k}\left(D_{k}\right)\right\}$参数化的**吉布斯分布**（Gibbs distribution）。

实际上马尔可夫网的因子分解是定义在团（完全子图）上的，有下面定义：

* 定义4.4
  假设每个$D_{k}(k=1, \cdots, K)$是$\mathcal{H}$的团，则称具有$\Phi=\left\{\phi_{1}\left(D_{1}\right), \cdots, \phi_{K}\left(D_{K}\right)\right\}$的分布$P_{\Phi}$在马尔可夫网$\mathcal{H}$上**因子分解**。参数化马尔可夫网的因子通常称为团位势（clique potential）。

这样因子定义在团上的好处是，团保留了原结构的独立性假设，所以导出的独立性假设不会被破坏。

* **==马尔可夫随机场因子分解的重新表达和理解==**
  在MRF中，<u>多个变量之间的联合概率分布能基于团分解为多个因子的乘积，每个因子仅与一个团相关，称为MRF的因式分解</u>，对于n个变量$Y=\left\{y_{1}, y_{2}, \dots, y_{n}\right\}$，假设无向图$\mathcal{H}$中所有团构成集合$C$，与团$Q \in C$对应的变量集合为$\mathrm{Y}_{\mathrm{Q}}$则MRF联合概率分布$\mathrm{P}(\mathrm{Y})$定义为：
  $$
  P(Y)=P\left(y_{1}, \ldots, y_{n}\right)=\frac{1}{Z} \prod_{Q \in C} \psi_{Q}\left(Y_{Q}\right)
  $$
  其中$Z$是归一化因子确保$P(Y)$构成一个概率分布：
  $$
  Z=\sum_{Y} \prod_{Q \in C} \psi_{Q}\left(Y_{Q}\right)=\sum_{y_{1}, \ldots, y_{n}} \prod_{Q\in C} \psi_{Q}\left(Y_{Q}\right)
  $$
  显然，若变量数较多，则团的数目将会很多，这将会给计算带来很大的负担。我们注意到，如果团$Q$不是即最大团，则它必然会被一个最大团$Q^{*}$所包含，即$\mathrm{Y}_{\mathrm{Q}} \in \mathrm{Y}_{\mathrm{Q}^{*}}$，这意味着变量$\mathrm{Y}_{\mathrm{Q}}$之间的关系不仅体现在势函数$\psi_{Q}$中，还体现在$\psi_{Q^{*}}$中。因此，我们可以简单一点，直接<u>基于极大团来定义联合概率分布$P(Y)$。</u>假设所有极大团构成的集合为$C^{*}$，则有：

$$
P(Y)=P\left(y_{1}, \ldots, y_{n}\right)=\frac{1}{Z^{*}} \prod_{Q \in C^{*}} \psi_{Q}\left(Y_{Q}\right)
$$
 	其中：
$$
Z^{*}=\sum_{Y} \prod_{Q \in C^{*}} \psi_{Q}\left(Y_{Q}\right)=\sum_{y_{1}, \ldots, y_{n}} \prod_{Q\in C^{*}} \psi_{Q}\left(Y_{Q}\right)
$$
 	再来看势函数$\psi_{Q}$，一般需要保证其非负性（也就是开头说的因子非负性），为了保证这一点通常将其定义为指数函数：
$$
\psi_{Q}\left(Y_{Q}\right)=\exp \left\{-E\left(Y_{Q}\right)\right\}
$$
 	其中$E\left(Y_{Q}\right)$称为$\mathrm{Y}_{\mathrm{Q}}$的能量函数，是一个定义在$\mathrm{Y}_{\mathrm{Q}}$上的实值函数，常见形式为：
$$
E\left(Y_{Q}\right)=\sum_{u, v \in Q, u \neq v} \alpha_{u v} y_{u} y_{v}+\sum_{v \in Q} \beta_{v} y_{v}
$$
 	，式中$\alpha_{u v}$和$\alpha_{v}$均为参数，式中<u>第二项考虑单节点，第一项考虑每一对节点的关系</u>。

* 一个直观的例子：
如下一个简单的马尔可夫随机场，可以直接找出他的最大团：$\left\{\mathrm{X}_{2}, \mathrm{X}_{5}, \mathrm{X}_{6}\right\},\left\{\mathrm{X}_{1}, \mathrm{X}_{2}\right\},\left\{\mathrm{X}_{2}, \mathrm{X}_{4}\right\},\left\{\mathrm{X}_{1}, \mathrm{X}_{3}\right\},\left\{\mathrm{X}_{3}, \mathrm{X}_{5}\right\}$，可以得到联合概率分布的因子分解形式：
$$
\begin{aligned}
&P(X)=P\left(x_{1}, x_{2}, x_{3}, x_{4}, x_{5}, x_{6}\right)\\
&=\frac{1}{Z} \psi_{256}\left(x_{2}, x_{5}, x_{6}\right) \psi_{12}\left(x_{1}, x_{2}\right) \psi_{24}\left(x_{2}, x_{4}\right) \psi_{13}\left(x_{1}, x_{3}\right) \psi_{35}\left(x_{3}, x_{5}\right)
\end{aligned}
$$
<img src="https://github.com/ming71/PGM/tree/master/pic/1580723161220.png" alt="1580723161220" style="zoom:67%;" />



##### 4.2.3  简化的马尔可夫网

* 定义4.5
  令$\phi(\boldsymbol{Y})$为一个因子，且$U=u$为$U \subseteq Y$的一个赋值，因子$\phi$关于上下文$U=u$的约简定义为辖域$Y^{\prime}=Y-U$的一个因子，记为$\phi[\boldsymbol{U}=\boldsymbol{u}]$（简写作$\phi[u]$），使得：
  $$
  \phi[\boldsymbol{u}]\left(\boldsymbol{y}^{\prime}\right)=\phi\left(\boldsymbol{y}^{\prime}, \boldsymbol{u}\right)
  $$
【理解】该定理的意思是，当变量的某个子集$U=u$值确定时，马尔可夫网的辖域简化为$Y-U$（也就是变量集$U$在马尔可夫网中可以去除掉），所有$U$不等于$u$的因子也可以不考虑了。结合下面的命题4.1更好理解。
  
* 命题4.1
  令$P_{\Phi}(X)$为一个吉布斯分布，则$P_{\mathrm{u}}[\boldsymbol{u}]=P_{\mathrm{u}}(\boldsymbol{W} | \boldsymbol{u})$，其中：$W=X-U$
由上面命题知，为了在已知上下文$u$的吉布斯分布上取条件，可以简单地将每个因子都简约到该上下文条件中。下面定义4.7进一步进行归纳：
  
* 定义4.7
  令$\mathcal{H}$为$\boldsymbol{X}$上的一个马尔可夫网，$U=u$为一个上下文，约简的马尔可夫网$\mathcal{H}[\boldsymbol{u}]$是节点集$W=X-U$上的一个马尔可夫网，其中，假设$\mathcal{H}$中有一条边$X-Y$，那么$\mathcal{H}[\boldsymbol{u}]$也有一条边$X-Y$。

* 命题4.2
令$P_{\Phi}(X)$为在图$\mathcal{H}$上因子分解的一个吉布斯分布，$U=u$为一个上下文，则$P_{\phi}[u]$可以在$\mathcal{H}[u]$上因子分解。

* 一个例子
如下图，在约简到上下文$G=g$时，就相当于在原因子集中去除和G相关的节点和边，后面类似。
【注意】这里的结构很简单，基于上下文取条件直接删除图中的节点和边即可；但是在贝叶斯网中基于证据取条件可能激活v-结构导致生成新的依赖关系。
<img src="https://github.com/ming71/PGM/tree/master/pic/1580783490794.png" alt="1580783490794" style="zoom:67%;" />

* 应用
马尔可夫网在计算机视觉中又称作马尔可夫随机场（MRF）,广泛引用于图像分割、去模糊和去噪、三维重建和物体识别等。在大分应用中，网络以成对MRF的形式呈现，其中变量对应于像素，而边（因子）对应表示图像的网格上相邻像素之间的相互影响。这样，每个（内部）像素都刚好有4个近邻节点。这些变量的取值空间和因子的精确形式取决于所处理的任务。这些模型通常用能量（负对数位势）来明确表达，这样的值代表了惩罚，并且一个较小的值对应着一个高概率的结构。
以图像分割任务为例，图像多类别的分割任务可以用马尔可夫随机场（确切的说是条件随机场方法）来完成。对于每个像素$X_{i}$有一个域$\{1, \cdots, K\}$，其值对应着区域类别的分配；由于像素太多计算量过大，往往先使用过分割的方法将图像划分为超像素作为图的节点；进而可以在每个超像素节点上进行特征提取，如颜色、纹理、亮度等，由于提取特征维度过高，还可以进行聚类降维处理，用所得到的低维特征作为模型特征；每个超像素的节点位势就是这些特征的一个函数；然后根据马尔可夫网的方法得到吉布斯分布构建节点及其之间的联系的概率分布。

##### 4.3  马尔可夫网的独立性

与在贝叶斯网中一样，马尔可夫网中的图结构也可以看作是对一系列独立性假设的编码。直观上，在马尔可夫网中，概率影响在图中沿着无向路径“流动”，但当我们对某些中间节点取条件时（观测），流动会受到阻碍。

##### 4.3.1  基本独立性

* 定义4.8
令$\mathcal{H}$表示一个马尔可夫网结构，$X_{1}-\cdots-X_{k}$是$\mathcal{H}$中的一条路径，令$\boldsymbol{Z} \subseteq \mathcal{X}$是观测变量的一个子集，若所有$X_{i}(i=1, \cdots, k)$的节点均不在$Z$中，路径$X_{1}-\cdots-X_{k}$在给定$Z$时是**有效路径**。

基于上述定义，可以进一步在图中定义分离的概念和独立性：
* 定义4.9
  如果给定$Z$时，任意两个节点$X \in \boldsymbol{X}$和$Y \in \boldsymbol{Y}$之间没有路径，那么称节点集$\boldsymbol{Z}$在$\mathcal{H}$中分离$\boldsymbol{X}$与$\boldsymbol{Y}$，记为$\operatorname{sep}_{H}(X ; Y | Z)$，即**全局独立性**：
  $$
  \mathcal{I}(\mathcal{H})=\left\{(\boldsymbol{X} \perp \boldsymbol{Y} | \boldsymbol{Z}): \operatorname{sep}_{\mathcal{H}}(\boldsymbol{X} ; \boldsymbol{Y} | \mathcal{Z})\right\}
  $$

* 定理4.1
  令$P$为$\mathcal{X}$上的一个分布，$\mathcal{H}$为$\mathcal{X}$上的一个马尔可夫网，如果$P$是在$\mathcal{H}$上因子分解的一个吉布斯分布，则$\mathcal{H}$是$P$的一个I-map。

  【注意】通过Hammersley-Clifford定理，可以将因子分解吉布斯分布和三个独立性连结起来。


* 定理4.2
令$P$为$\mathcal{X}$上的一个分布，$\mathcal{H}$为$\mathcal{X}$上的一个马尔可夫网，如果$\mathcal{H}$是$P$的一个I-map，则$P$可以是在$\mathcal{H}$上因子分解的一个吉布斯分布。
【在正分布的情况下，对于正分布，个局独立性意味着分布可以根网络结构因了分解，此时定理4.1和4.2是充要的】

##### 4.3.2  独立性回顾

######  4.3.2.1  局部马尔可夫假设

* ==**成对独立性**==：令$\mathcal{H}$表示一个马尔可夫网结构，成对独立性定义如下：
  $$
  \mathcal{I}_{p}(\mathcal{H})=\{(X \perp Y | \mathcal{X}-\{X, Y\}): X-Y \notin \mathcal{H}\}
  $$
【解读】在给定<u>非邻</u>节点$X,Y$以外所有节点变量条件下，$X,Y$独立。
* ==**局部独立性**==：对于给定的图$\mathcal{H}$，$X$在$\mathcal{H}$中的马尔可夫毯$\mathrm{MB}_{\mathcal{H}}(X)$定义为$X$在$\mathcal{H}$中的近邻。则局部独立性假设定义如下：
$$
\mathcal{I}_{i}(\mathcal{H})=\left\{\left(X \perp \mathcal{X}-\{X\}-\mathrm{MB}_{M}(X) | \mathrm{MB}_{\mathcal{H}}(X)\right): X \in \mathcal{X}\right\}
$$
【解读】给定近邻后，$X$与其他的所有节点独立

######  4.3.2.2  马尔可夫性质之间的关系

对正分布而言，马尔可夫全局独立性、成对独立性和局部独立性三者等价。

##### 4.3.3  从分布到图

* **马尔可夫毯**：如果$X \notin U$且$\boldsymbol{U}$是满足如下条件的最小集：
  $$
  (X \perp \mathcal{X}-\{X\}-\boldsymbol{U} | \boldsymbol{U}) \in \mathcal{I}(P)
  $$
则称$U$为$X$在分布$P$中的一个马尔可夫毯。
  

【理解】也就是，给定变量集合$\boldsymbol{U}$时，不在$\boldsymbol{U}$中的节点$X$与剩下所有节点均独立。打个比方，给定你身边所有认识的人条件下，你和社会上其他人是没有联系（独立）的。在贝叶斯网络中，利用局部独立性知，某节点的马尔可夫毯就是其父节点、子节点、以及子节点的父节点。

#### 4.4  参数化回顾

#####  4.4.1  细粒度参数化方法

###### 4.4.1.1  因子图

马尔可去网结构通常不能揭示吉布斯参数化中的所有结构，因而需要其他的表示方法即因子图。因子图是包含两类节点的图：其中一类与往常一样与随机变量对应，另一类则与变量上的因子对应。正式定义如下：
* 定义4.13
  因子图$\mathcal{F}$是包含两类节点的无向图：变量节点（用椭圆表示）和因子节点（用方框表示）。这种图<u>只包含变量节点与因子节点之间的边</u>。因子图$\mathcal{F}$由系列因子参数化，其中每个因子节点$V_{\phi}$与因子$\phi$相关联，其辖域是图中与$V_{\phi}$相邻的节点的变量集。假如分布$P$可以表示成一系列这种形式的因子，那么分布$P$在$\mathcal{F}$上因子分解。
【示例】下图很好地揭示了因子图的优点，（a）（b）的马尔可夫网都是（c），但是因子分解形式不同，其中（a）在所有变量上只有单一因子（可以是三者相加、相乘等运算）；而（b）的因子连结的是两两成对的节点进行函数映射。
  
  <img src="https://github.com/ming71/PGM/tree/master/pic/1580792274266.png" alt="1580792274266" style="zoom:67%;" />

###### 4.4.1.2  对数线性模型

一般为了保证正分布的成立，取得因子形式为：
$$
\phi(\boldsymbol{D})=\exp (-\epsilon(\boldsymbol{D}))
$$
其中$\epsilon(D)=-\ln \phi(D)$称为能量函数，将之代入概率分布中利用指数函数的特点将因子分解的累乘改为累加：$P\left(X_{1}, \cdots, X_{n}\right) \propto \exp \left[-\sum_{i=1}^{m} \epsilon_{i}\left(D_{i}\right)\right]$，这和指数分布族殊途同归。

* 定义4.14
令$D$是变量的一个子集。特征$f(\boldsymbol{D})$定义为从哪个$\operatorname{Val}(\boldsymbol{D})$到$R$的一个函数。
（特征是没有丰负要求的一个因子，这也更符合实际应用的情况）一类比较常用的特征是指示特征（indicator feature），该特征对于某些值$y \in \operatorname{Val}(D)$取1，其他值取0。
一般化对数线性模型定义：
* 定义4.15
假如分布$P$与：
	* 特征集$\mathcal{F}=\left\{f_{1}\left(\boldsymbol{D}_{1}\right), \cdots, f_{k}\left(\boldsymbol{D}_{k}\right)\right\}$，其中每个$D_{i}$是$\mathcal{H}$中的一个完全子图，
	* 一系列权重$\omega_{1}, \cdots, \omega_{k}$，
相关，并使得：
$$
P\left(X_{1}, \cdots, X_{n}\right)=\frac{1}{Z} \exp \left[-\sum_{i=1}^{k} \omega_{i} f_{i}\left(D_{i}\right)\right]
$$
那么分布$P$是马尔可夫网$\mathcal{H}$上的一个对数线性模型（log-linear model）。

###### 4.4.1.3  讨论

现在己经具备了马尔可夫网参数化的三种表示。其中，马尔可夫网表示团位势的乘积，因子图表示因子的乘积；特征集则在特征权重上表示乘积。显然，每种表示都比前一种表示更加精细而且同样丰富。因子图可以描述吉布斯分布，特征集则可以在因子图的每个因子中表示所有的表值。

##### 4.4.2  过参数化

#### 4.5 贝叶斯网与马尔可夫网

本部分将讨论两种网络的深层联系和转化方法。

暂略。

---