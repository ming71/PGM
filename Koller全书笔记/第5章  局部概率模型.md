### 第五章  局部概率模型

#### 5.1  CPD表

就是联合概率分布的概率查询表，毫无疑问参数个数容易爆炸导致实用性不强。出现这种现象是因为我们忽视了CPD表中的内在结构（如独立性），本章讨论的重点就是描述并利用变量之间的内在结构关系进而简化CPD表的参数量。

#### 5.2  确定性CPD

##### 5.2.1 表示

当变量$X$是其父节点$\mathrm{Pa}_{\mathrm{X}}$的一个<u>确定性函数</u>时，就得到了一类最简单的非表格条件概率。即存在一个函数$f: \operatorname{Val}\left(\mathrm{Pa}_{x}\right) \mapsto \operatorname{Val}(X)$使得：
$$
P\left(x | \text { pa }_{x}\right)=\left\{\begin{array}{ll}
{1,} & {x=f\left(\text { pa }_{x}\right)} \\
{0,} & {\text {其他 }}
\end{array}\right.
$$
##### 5.2.2  独立性

引入确定性关系后，可能得到<u>额外的独立性关系</u>。例如下图：

如果$C$不是确定性关系导出，那么给定$A$和$B$的条件下，d-分离并不能导出$D$和$E$相互独立。但是如果$C$是$A$和$B$的确定性函数，那么给定$A$和$B$时，$C$是可以确定的，在给定$C$下易知$D$和$E$独立，即$(D \perp E | A, B)$在该分布成立。

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581129728245.png" alt="1581129728245" style="zoom:67%;" />

根据上面的例子可知，$C$虽然不可观测，但是仍应该属于观测集，从而可以扩充观测集来回归到利用d-分离解决问题，上面的问题可以转化为$(D \perp E | A, B, C)$，从而可以用d-分离解决。

==【**在确定性CPD存在的条件下计算d-分离**】==

$DET-SEP(\mathcal{G},D,X,Y,Z)$    //  $\mathcal{G}$是网络结构; $D$是确定性关系集合; $X,Y,Z$是查询集合  
1. 根据现有观测集$Z$找到所有确定性关系能够确定的额外变量
2. 将这些变量纳入中观测集$Z$中，得到扩展的观测集$Z^+$
3. 进行d-分离$\mathrm{d}-\operatorname{sep}_{G}\left(\boldsymbol{X} ; \boldsymbol{Y} | \boldsymbol{Z}^{+}\right)$，称给定$Z$的条件下，$\mathbf{X}$确定性地与$\mathbf{Y}$分离。

再给一个例子练习：
下图中，$C$是$A$和$B$抑或确定的，那么分布中成立：$(D \perp E | B, C)$。给定了$B$和$C$，根据确定性关系知$A$也可以确定，加入到观测集，从而实际是：$(D \perp E | A, B, C)$，就可以证了。

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581133106590.png" alt="1581133106590" style="zoom:67%;" />

**讨论**：

以上面的图5.1为例，上例中给定的是$A$和$B$从而由确定性关系导出$C$是已知的，那么换个角度如图5.2这样，如果在图5.1中给定的是$A$和$C$呢？或者更多的不确定性呢？即例5.5，假设$C$的确定函数是$OR$，给定证据为$A=a^{1}$，那么不论$B$取何值，立马有$C=c^{1}$，此时$B$和$D$独立，可表示为：$P\left(D | B, a^{1}\right)=P\left(D | a^{1}\right)$；但是如果给定$A=a^{0}$，$C$的值不定取决于为给定的$B$，而不能得出$B$已知导致$A=a^{0}$下上面的独立性声明不成立，可知在确定性关系下，证据不能只给$A$而是有关于其具体取值。

因此确定性变量可以导出一种与迄今为上我们所关注的标准概念不同的独立性形式。到目前为止，我们一直把注意力限制在形如$(X \perp Y | Z)$的独立性质上。这种性质代表了这样的假设：$P(X | Y, Z)=P(X | Z)$对于所有取值的$X, Y , Z$都成立。<u>确定性函数能够蕴含一类仅对**某些变量的特殊值**成立的独立性。</u>导出如下定义：

* 定义5.1 
  令$X, Y, Z$为两两互不相交的变量的集合，令$C$是变量的一个集合（可能与$X \cup Y \cup Z$有交集），且令$c \in V a l(C)。如果：
  $$
  P(X | Y, Z, c)=P(X | Z, c)
  $$
  其中$P(\boldsymbol{Y}, \boldsymbol{Z}, \boldsymbol{c})>0$，则称$X, Y$在给定$ Z$和上下文$c$时==**上下文独立**==（contextually independent），记为$\left(\boldsymbol{X} \perp_{c} \boldsymbol{Y} | \boldsymbol{Z}, \boldsymbol{c}\right)$

这种形式的独立性声明称为**上下文特定的独立性**（context-specificindependencies，**CSI**）

* 例5.6
  例如上面讨论上下文时的例子，给定$A=a^{1}$时$C$的值唯一决定无关于$B$，可表示为$\left(C \perp_{c} B | a^{1}\right)$；同理进一步有$\left(D \perp B | a^{1}\right)$。此外，如果已知$C=c^{0}$可以推出$A=a^{0} ， B=b^{0}$，由此得到$\left(A \perp_{c} B | c^{0}\right)$ 和$\left(D \perp_{c} E | c^{0}\right)$。

#### 5.3  特定上下文CPD

##### 5.3.1  表示

* 例5.8
现将学生示例扩展为学生在咨询公司获得一份工作的模拟，如下有向图表示。新加的一个二值变量$J$，如果学生获得工作，取值为$j^1$否则$j^0$；还有一个二值变量$A$，代表学生是否求职。现需要对$\operatorname{CPD} P(J | A, S, L)$进行描述，满足条件如下：
1. 假定学生即使不求职（$a_0$），但如果公司极其需要员工，为其提供工作，那么学生可能回心转意仍有机会获得工作（$j^1$）。但此时公司不再考虑Letter和SAT变量取值--能来就行。此时在三个父节点8种可能中，$A=a^{0}$的四个情况下需要在$J$中导出统一分布。
2. 进一步复杂化，假定招聘者认为SAT成绩比推荐信更能反映学生智力水平，如果SAT高就立马发出录用；而SAT低再看推荐信如何再做决定，那么有$P\left(J | a^{1}, s^{1}, l^{1}\right)=P\left(J | a^{1}, s^{1}, l^{0}\right)$

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581136961185.png" alt="1581136961185" style="zoom:67%;" />
###### 5.3.1.1  树-CPD

在CPD中获取公共元素的一种非常自然的表示是树，其中树的叶节点代表定义在$J$上的不同的可能（条件）分布，通往每个叶节点的路径则决定了使用这个分布的上下文。

* 例5.8
提到的$\operatorname{CPD} P(J | A, S, L)$可以用下面CPD树表示。叶节点表示的是$J$的条件分布，条件是走过的路径。比如对$P\left(J | a^{1}, s^{1}, l^{0}\right)$感兴趣，则路径是$a^{1}$-$s^{1}$达到一个叶子结点，从而得到分布为$p\left(j^{1}\right)=0.9$和$p\left(j^{0}\right)=0.1$，没必要继续往下搜索，说明当前分布无关于变量$L$的取值。这和假设一致：知道SAT成绩是高，那么可以直接给工作，无关Letter质量高低。

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581141616857.png" alt="1581141616857" style="zoom:67%;" />

* 定义5.2
  关于变量$X$，表示CPD的树-CPD是一颗有根的树：树上的每个t-节点或者是一个叶子的t-结点或者是一个内部的t-节点。
  每个叶节点由分布$P(X)$标记，每个内部t-节点山某个变量$Z \in \mathrm{Pa}_{X}$标记。每个内部t-节点有指向其子节点的弧的一个集合$z_{i} \in \operatorname{Val}(Z)$，每条弧与唯一的变量赋值$Z=z_{i}$关联。

树CPD上的<u>树枝</u>$\beta$是从树根开始，通向叶子结点的一条路径。

* 例5.10
现在学生George手握两封推荐信$L_{1}$和$L_{2}$，这两封推荐信他会选一个交给咨询公司，而选出的推荐信决定他能否获得这个工作。这个例子中，显然两个推荐信变量$L_{1}$和$L_{2}$都是工作机会$J$的父节点，但是当George做出选择$C$后，只依赖两者之一。这是一种特殊的结构，可以用如下图表示：

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581144664184.png" alt="1581144664184" style="zoom:67%;" />

* 定义5.3
如果$\operatorname{Val}(A)=\{1, \ldots, k\}$，且$P\left(Y | A, Z_{1}, \cdots, Z_{k}\right)=I\left\{Y=Z_{a}\right\}$，其中$a$是$A$的值，变量$A$称为CPD的**选择器变量**（selector variable）。则$\operatorname{CPD} P\left(Y | A, Z_{1}, \cdots, Z_{k}\right)$称为一个**多路复用器CPD**（multiplexr CPD）。

即选择器变量的值是其父节点$Z_{1}, \cdots, Z_{k}$之一值的拷贝，$A$扮演的角色是被拷贝的父节点。可以认为多路复用器CPD是一个多路开关。

###### 5.3.1.2  规则CPD

树是全局的表示，规则CPD能实现特定上下文依赖的细粒度表示。每个规则对应CPD中的一项，说明该项所应用的上下文及其取值。规则可以看成是CPD或是联合分布的分解。

###### 5.3.1.3  其他表示

##### 5.3.2  独立性

* 定义5.7
令$P\left(X | \mathrm{Pa}_{X}\right)$是一个CPD，$Y \in \mathrm{Pa}_{X}$，并且令$c$是一个上下文。如果$P\left(X | \mathrm{Pa}_{X}\right)$满足：$\left(X \perp_{c} Y | \mathrm{Pa}_{x}-\{Y\}, c^{\prime}\right)$，则称边$Y \rightarrow X$在上下文$c$中是**伪**（spurious）的，其中$c^{\prime}=c\left\langle\mathrm{Pa}_{X}\right\rangle$是$c$对$\mathrm{Pa}_{\mathrm{X}}$中变量的约束。

如果用规则表示CPD，那么通过检查约简规则集，即可确定一条边是否为伪的。令$R$为$\mathrm{Pa}_{\mathrm{X}}$的基于规则的CPD，如果$Y$没有出现在约简规则集$R[c]$中，那么$Y \rightarrow X$边是伪的。

有了伪边定义，可以定义==**CSI-分离**==：在给定$Z$的条件下，如果$\mathrm{CSI}-\operatorname{sep}(\mathcal{G}, c, X, Y, Z)$返回为真，称$X$与$Y$在上下文$c$中CSI-分离，记作$P \vDash\left(X \perp_{c} Y | Z, c\right)$。CSI-分离是将上下文考虑进去后的一种改进d-分离，流程很简单，对给定的图在局部删除伪边，然后得到的图进行d-分离。

例如上面图5.3，可以得到如下两个示例：

（a）中，给定$A=a^{0}$，则考虑节点$A$的局部父子关系有父节点$L, A, S$，子节点$J$，由于给定父节点上下文$A=a^{0}$，在已知学生不申请工作情况下，他能否得到这份工作（$J$），和他的推荐信质量、SAT成绩无关，所以$S \rightarrow J$和$L \rightarrow J$是伪边，删去，得到下图（a），进而d-分离可得，$J$和$D$是d-分离的。可以称作：$I \vDash\left(J \perp_{a_0} Y | a_0\right)$

（b）中给定的上下文时$S=s^{1}$，则考虑局部模型$L, A, J, S$，已知SAT成绩高的情况，面试官会无视Letter好坏，所以给定$S=s^{1}$，$I$和$J$独立，删去该伪边得到如下（b）图

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581153729548.png" alt="1581153729548" style="zoom:67%;" />

再如，之前的Gergeo有两封推荐信的假设，如果他选择递交$L_1$给面试官，那么他的能否得到工作和另一封$L_2$独立，所以$L_2 \rightarrow J$是伪边，反之同理。

#### 5.4  因果影响的独立性

考虑一个变量$Y$，其由若干原因$X_{1}, \cdots, X_{k}$共同作用，一般而言这些原因之间会进行复杂的组合和相互作用进而影响最终结果。但大多数情况下，我们面对的都是线性系统，也就是说，其满足**叠加原理**，每一个$X_{i}$对$Y$有单独的影响，总的影响可以看成这些单独影响的线性组合。

下面从两个非常有用的模型入手，再对这类交互作用总结其一般定义。

##### 5.4.1  Noisy-or模型

仍然是学生示例，现在只考虑推荐信，教授给学生写的推荐信（$L$）取决于两件事：她是否上课回答问题（$Q$）以及她结课论文（$F$）写的怎么样。然而可能时间过长教授忘了学生上课是否回答问题，同时教授还可能不小心漏掉了看你的结课论文导致评价不好。现假设，不好的推荐信只有在两个条件都不满足时产生，两事件是独立作用的。此外教授有80%可能性记得她上课回答过问题表示为$P\left(l^{1} | q^{1}, f^{0}\right)=0.8$，90%可能性审阅了她的结课论文（假设她的论文一定写的很好）表示为$P\left(l^{1} | q^{0}, f^{1}\right)=0.9$。那么她的推荐信结果概率分布$P(L | Q, F)$的CPD为：
$$
\begin{array}{cc|cc}
{Q,} & {F} & {l^{0}} & {l^{\prime}} \\
\hline q^{0} & {f^{0}} & {1} & {0} \\
{q^{0}} & {f^{\prime}} & {0.1} & {0.9} \\
{q^{\prime}} & {f^{0}} & {0.2} & {0.8} \\
{q^{\prime}} & {f^{\prime}} & {0.02} & {0.98}
\end{array}
$$
这样的原因存在扰动的交互作用就是Noisy-or模型，特点是其每个确定性关系原因都存在一定噪声。可以用图来表示更加直观：

<img src="C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\1581165238543.png" alt="1581165238543" style="zoom:67%;" />

由$Q$引起$L$的概率（这里是0.8）称为噪声参数，记作$\lambda_{Q}$，在上下文的条件概率表示为$\lambda_{Q}=P\left(q^{\prime 1} | q^{\prime}\right)$。对于变量$F$有类似的结论。再定义一个**泄露概率**（leak probability），表示教授在没有任何好理由情况下却写了好的推荐信，该节点显然也是Letter的一个确定性关系为$OR$的父节点。更一般的定义如下：

* 定义5.8
令$Y$是有$k$个二值父节点$X_{1}, \cdots, X_{k}$的一个二值随机变量，如果满足：
$$
\begin{aligned}
&P\left(y^{0} | X_{1}, \ldots, X_{k}\right)=\left(1-\lambda_{0}\right) \prod_{i: X_{i}=x_{i}^{1}}\left(1-\lambda_{i}\right)\\
&P\left(y^{1} | X_{1}, \ldots, X_{k}\right)=1-\left[\left(1-\lambda_{0}\right) \prod_{i: X_{i}=x_{i}^{1}}\left(1-\lambda_{i}\right)\right]
\end{aligned}
$$
的$k+1$个噪声参数$\lambda_{0}, \lambda_{1}, \cdots, \lambda_{k}$，则$\operatorname{CPD} P\left(Y | X_{1}, \cdots, X_{k}\right)$是一个noisy-or CPD。

该模型应用的场景很多，最常用的是医学领域。

##### 5.4.2  广义线性模型

首先讨论二值情况然后推广到多值变量，并讨论其独立性。

###### 5.4.2.1  二值变量

一个生物学的例子：人体的免疫系统每与一种外界病原体斗争，都会对应增加其一定的负担，当总负担超过一定阈值身体开始出现一定症状，包括发烧等。这里需要讨论两项：一是总负担如何依赖于各种疾病；二是总负担怎么影响发烧的。

假定各种疾病是给定二值变量为$X_{1}, \cdots, X_{k}$，发烧与否是二值变量$Y$，总负担是各个疾病造成负担之和$f\left(X_{1}, \cdots, X_{k}\right)=\sum_{i=1}^{k} w_{i} X_{i}$，其中权重系数是每种单独疾病造成的负担量。发烧$Y=y^{1}$依赖于$f\left(X_{1}, \cdots, X_{k}\right)$，一般存在一个阈值$\tau$，$f\left(X_{1}, \cdots, X_{k}\right) \geqslant \tau$时$Y$可能为1，反之为0，移项一下，并令$w_{0}=-\tau$得到：$f\left(X_{1}, \cdots, X_{k}\right)=w_{0}+\sum_{i=1}^{k} w_{i} X_{i}$用于判断发烧。一般而言阈值函数取得是sigmoid函数，相对平滑。这样一来，正常人的负担很小，概率趋近0不发烧；发烧严重的人负担很大，概率接近1；介于两者中间的人负担随发烧概率呈线性增长。

对该模型有如下正式定义：

* 定义5.9
令$Y$是一个有$k$个父节点$X_{1}, \cdots, X_{k}$的二值变量，如果存在$k+1$个权重$w_{0}, w_{1}, \cdots, w_{k}$使得：
$$
P\left(y^{1} | X_{1}, \cdots, X_{k}\right)=\operatorname{sigmoid}\left(w_{0}+\sum_{i=1}^{k} w_{i} X_{i}\right)
$$
则称$\operatorname{CPD} P\left(Y | X_{1}, \ldots, X_{k}\right)$为logistic CPD。

###### 5.4.2.2  多值变量

* 定义5.10
	令$Y$是一个有$k$个父节点$X_{1}, \cdots, X_{k}$的$m$值变量，如果每个$j=1, \cdots, m$，存在$k+1$个权重$w_{j, 0}, w_{j, 1}, \cdots, w_{j, k}$使得：	
$$
\begin{aligned}
\ell_{j}\left(X_{1}, \ldots, X_{k}\right) &=w_{j, 0}+\sum_{i=1}^{k} w_{j, i} X_{i} \\
P\left(y^{j} | X_{1}, \ldots, X_{k}\right) &=\frac{\exp \left(\ell_{j}\left(X_{1}, \ldots, X_{k}\right)\right)}{\sum_{j^{\prime}=1}^{m} \exp \left(\ell_{j^{\prime}}\left(X_{1}, \ldots, X_{k}\right)\right)}
\end{aligned}
$$
则称$\operatorname{CPD} P\left(Y | X_{1}, \ldots, X_{k}\right)$为多项式 logistic CPD。

##### 5.4.3  一般化公式表示

上面两个模型都是一般类局部概率模型的特例，都满足称作因果独立性（casual independence）或因果影响的独立性（independence of casual influence，ICI）。这些模型共同的性质：多重影响可以被分解为单独影响。

##### 5.4.4 独立性

#### 5.5 连续变量

* 定义5.14
  令$Y$是有连续父节点$X_{1}, \cdots, X_{k}$的连续变量，假如存在参数$\beta_{0}, \cdots, \beta_{k}$和$\sigma^{2}$使得：
  $$
  P\left(Y | x_{1}, \cdots, x_{k}\right)=\mathcal{N}\left(\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{k} x_{k} ; \sigma^{2}\right)
  $$
则称$Y$有一个**线性高斯模型**。该模型用向量表示为：
  $$
P(Y | \boldsymbol{x})=\mathcal{N}\left(\beta_{0}+\boldsymbol{\beta}^{\mathrm{T}} \boldsymbol{x} ; \sigma^{2}\right)
  $$
变量$Y$是$X_{1}, \cdots, X_{k}$外加均值0方差$\sigma^{2}$的线性函数：$Y=\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{k} x_{k}+\epsilon$，其中$\epsilon$是均值0方差$\sigma^{2}$的高斯噪声（例如给定$X_{1}=x_1, \cdots, X_{k}=x_k$情况下，$Y$服从均值$\beta_{0}+\beta_{1} x_{1}+\cdots+\beta_{k} x_{k}$、方差$\sigma^{2}$的正态分布）。
  

线性高斯模型，线性体现在以条件参数线性组合决定当前分布，高斯性体现在高斯分布的随机扰动。

例如$P(X | U)$的线性高斯CPD，其中$\epsilon$定义同上，$X=\beta_{0}+\beta_{1} u_{1}+\cdots+\beta_{k} u_{k}+\epsilon$，则概率密度表示：
$$
P(x | \boldsymbol{u})=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left\{-\frac{1}{2 \sigma^{2}}\left(x-\left(\beta_{0}+\beta_{1} u_{1}+\cdots+\beta_{k} u_{k}\right)\right)^{2}\right\}
$$

##### 5.5.1  混合模型

讨论完离散和连续变量后，现在讨论合并了离散和连续变量的模型，这种模型中必须处理具有离散和连续父节点的离散、连续变量。

先考虑子节点连续的情况，如果忽略离散父节点，我们可以简单地将$X$的CPD简单表示为$X$的连续父节点的线性高斯函数。使连续变量$X$依赖于离散变量$U$的最简单方法是对每个离散父节点的值定义一个不同参数集：

* 定义5.15
令$X$是一个连续变量，并且令$U=\left\{U_{1}, \cdots, U_{m}\right\}$是其离散父节点，$Y=\left\{Y_{1}, \cdots, Y_{k}\right\}$是其连续父节点。如果对任意值$u \in \operatorname{Val}(U)$，存在包含$k+1$个参数$a_{u, 0}, \cdots, a_{u, k}$的集合和方差$\sigma_{u}^{2}$，使得：
$$
p(X | \boldsymbol{u}, \boldsymbol{y})=\mathcal{N}\left(a_{u, 0}+\sum_{i=1}^{k} a_{u, i} y_{i} ; \sigma_{u}^{2}\right)
$$
则称$X$具有**条件线性高斯CPD**$(\mathrm{CLG} \mathrm{CPD})$。

* 定义5.16
如果一个贝叶斯网的每个离散变量只包含离散父节点，且每个连续变量都有一个CLG CPD，该贝叶斯网称为一个CLG网（**条件线性高斯网**）。
另一类问题就是要处理连续父节点下离散的子节点。这类问题在现实中是存在的，如父节点时温度变量，子节点是热水阀门开关的二值变量。这类问题可以用logistic CPD或多项式logistic CPD加以处理。

#### 5.6  条件贝叶斯网

* 定义5.17
在给定$X$条件下，$Y$上的条件贝叶斯网$\mathcal{B}$定义为节点是$X \cup Y \cup Z$的一个有向无圈图$\mathcal{G}$，其中$X, Y, Z$互不相交。$X$中的变量称为输入，$Y$中的变量称为输出，而$Z$中的变量是封装的。$X$中的变量在$\mathcal{G}$中没有父节点。$Z \cup Y$中的变量与一个CPD相关联。网络用链式法则定义了如下分布：
$$
P_{B}(\boldsymbol{Y}, \boldsymbol{Z} | \boldsymbol{X})=\prod_{X \in Y \cup Z} P\left(X | \mathrm{Pa}_{X}^{\mathcal{G}}\right)
$$
分布$P_{B}(\boldsymbol{Y} | \boldsymbol{X})$定义为$P_{B}(\boldsymbol{Y}, \boldsymbol{Z} | \boldsymbol{X})$的边缘：
$$
P_{B}(Y | X)=\sum_{Z} P_{B}(Y, Z | X)
$$
